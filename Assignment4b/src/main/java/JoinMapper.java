import autogeneratedProto.Building;
import autogeneratedProto.Employee;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
import org.apache.hadoop.hbase.mapreduce.TableMapper;
import org.apache.hadoop.hbase.mapreduce.TableSplit;
import org.apache.hadoop.hbase.util.Bytes;
import org.apache.hadoop.io.IntWritable;

import java.util.Arrays;

public class JoinMapper extends TableMapper<IntWritable, Result> {
    private static byte[] EMPLOYEE_TABLE = Bytes.toBytes("emplo");
    private static byte[] BUILDING_TABLE = Bytes.toBytes("buildi");

    @Override
    public void map(ImmutableBytesWritable rowKey, Result columns, Context context) {

        TableSplit currentSplit = (TableSplit) context.getInputSplit();                  // get table name
        byte[] tableName = currentSplit.getTableName();

        System.out.println(tableName.toString());
        try {
            if (Arrays.equals(tableName, EMPLOYEE_TABLE)) {

                Employee employee = Employee.parseFrom(columns.value());
                int building_code = employee.getBuildingCode();
                context.write(new IntWritable(building_code), columns);
            } else if (Arrays.equals(tableName, BUILDING_TABLE)) {

                Building building = Building.parseFrom(columns.value());
                int building_code = building.getBuildingCode();
                context.write(new IntWritable(building_code), columns);
            }
        } catch (Exception e) {
            // TODO : exception handling logic
            e.printStackTrace();
        }
    }
}